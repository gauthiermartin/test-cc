model_list:
  - model_name: "openai/*" # all requests where model not in your config go to this deployment
    litellm_params:
      model: openai/* # set `openai/` to use the openai route
      api_key: os.environ/OPENAI_API_KEY
    model_info:
      health_check_model: openai/gpt-4o-mini # specific model for health checks
  - model_name: "anthropic/*"
    litellm_params:
      model: anthropic/*
      api_key: os.environ/ANTHROPIC_API_KEY
    model_info:
      health_check_model: anthropic/claude-3-5-sonnet-20241022 # specific model for health checks

litellm_settings:
  check_provider_endpoint: true # Enable checking provider endpoint for wildcard models
